{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZHdDjOgOMbeGmCzHkTt6g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')\n","import os\n","os.chdir(\"/content/drive/My Drive/COLAB BB\")"],"metadata":{"id":"Mu-7RicpyIlr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Dataset Asli**"],"metadata":{"id":"gjruH_Ztt5S9"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def tampilkan_gambar(daftar_gambar):\n","    fig, axs = plt.subplots(3, 4, figsize=(18, 18))\n","    for i in range(3):\n","        for j in range(4):\n","            idx = i * 4 + j\n","            if idx < len(daftar_gambar):\n","                axs[i, j].imshow(daftar_gambar[idx])\n","            axs[i, j].axis('off')\n","    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.1, hspace=0.1)\n","    plt.show()\n","\n","gambar_1 = plt.imread('Salinan ke-1.jpeg')\n","gambar_2 = plt.imread('Salinan ke-2.jpeg')\n","gambar_3 = plt.imread('Salinan ke-3.jpeg')\n","gambar_4 = plt.imread('Salinan ke-4.jpeg')\n","gambar_5 = plt.imread('Salinan ke-5.jpeg')\n","gambar_6 = plt.imread('Salinan ke-6.jpeg')\n","gambar_7 = plt.imread('Salinan ke-7.jpeg')\n","gambar_8 = plt.imread('Salinan ke-8.jpeg')\n","gambar_9 = plt.imread('Salinan ke-9.jpeg')\n","gambar_10 = plt.imread('Salinan ke-10.jpeg')\n","\n","daftar_gambar = [gambar_1, gambar_2, gambar_3, gambar_4, gambar_5, gambar_6, gambar_7, gambar_8, gambar_9, gambar_10]\n","tampilkan_gambar(daftar_gambar)"],"metadata":{"id":"0Rhchpb4t4F1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Tampilan Dataset Setelah melalui proses**\n","\n","\n","*   Cropping image\n","*   Mengubah bayangan dalam gambar\n","\n"],"metadata":{"id":"_iKFWDfna60m"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","def tampilkan_gambar(daftar_gambar):\n","    fig, axs = plt.subplots(3, 4, figsize=(18, 8))\n","    for i in range(3):\n","        for j in range(4):\n","            idx = i * 4 + j\n","            if idx < len(daftar_gambar):\n","                axs[i, j].imshow(daftar_gambar[idx])\n","            axs[i, j].axis('off')\n","    plt.subplots_adjust(left=None, bottom=None, right=None, top=None, wspace=0.1, hspace=0.1)\n","    plt.show()\n","\n","gambar_1 = plt.imread('Hal1.jpg')\n","gambar_2 = plt.imread('Hal2.jpg')\n","gambar_3 = plt.imread('Hal3.jpg')\n","gambar_4 = plt.imread('Hal4.jpg')\n","gambar_5 = plt.imread('Hal5.jpg')\n","gambar_6 = plt.imread('Hal6.jpg')\n","gambar_7 = plt.imread('Hal7.jpg')\n","gambar_8 = plt.imread('Hal8.jpg')\n","gambar_9 = plt.imread('Hal9.jpg')\n","gambar_10 = plt.imread('Hal10.jpg')\n","\n","daftar_gambar = [gambar_1, gambar_2, gambar_3, gambar_4, gambar_5, gambar_6, gambar_7, gambar_8, gambar_9, gambar_10]\n","tampilkan_gambar(daftar_gambar)"],"metadata":{"id":"3c2qUlcubWS_"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Pre-processing**\n","- Warna ke Biner\n","- Thresholding"],"metadata":{"id":"9sZwbLtEuJnC"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def ubah_ke_biner(gambar, threshold):\n","    img = cv2.imread(gambar, cv2.IMREAD_GRAYSCALE)\n","    _, biner = cv2.threshold(img, threshold, 255, cv2.THRESH_BINARY)\n","    return biner\n","\n","def tampilkan_gambar(gambar):\n","    plt.imshow(gambar.astype('float32'), cmap='gray')\n","    plt.axis('off')\n","    plt.show()\n","\n","gambar_awal = 'Hal6.jpg'\n","threshold = 127\n","\n","gambar_biner = ubah_ke_biner(gambar_awal, threshold)\n","tampilkan_gambar(gambar_biner)"],"metadata":{"id":"9PbdopcPz6cn"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Resize**"],"metadata":{"id":"Av7xHdluuUPT"}},{"cell_type":"code","source":["import cv2\n","from google.colab.patches import cv2_imshow\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","\n","# Resize citra\n","resized_image = cv2.resize(gambar_biner, (512, 512))\n","\n","# Tampilkan citra hasil resize\n","plt.imshow(resized_image, cmap='gray')\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"GmC7qnhUubxU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Morfologi Citra**"],"metadata":{"id":"sSlcnbFAyYWv"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Erosi\n","kernel = np.ones((3, 3), np.uint8)\n","eroded_image = cv2.erode(resized_image, kernel, iterations=1)\n","\n","# Dilasi\n","#kernel = np.ones((3, 3), np.uint8)\n","#dilated_image = cv2.dilate(resized_image, kernel, iterations=1)\n","\n","# Tampilkan citra hasil erosi dan dilasi\n","plt.imshow(eroded_image, cmap='gray')\n","#plt.imshow(dilated_image, cmap='gray')\n","plt.axis('off')\n","plt.show()"],"metadata":{"id":"E6A3fgvQyc5l"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Bounding Box**"],"metadata":{"id":"HSrBy2Mnyh75"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Mengasumsikan eroded_image adalah gambar sumber sebelum diresize\n","\n","resized_image2 = cv2.resize(eroded_image, (512, 512))\n","\n","# Convert gambar menjadi RGB agar kompatibel dengan matplotlib\n","resized_image2_rgb = cv2.cvtColor(resized_image2, cv2.COLOR_BGR2RGB)\n","\n","# Find the contours in the image\n","contours, hierarchy = cv2.findContours(resized_image2, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","\n","# Find the bounding boxes of the contours\n","bounding_boxes = [cv2.boundingRect(c) for c in contours]\n","\n","# Draw the bounding boxes on the image with the desired color\n","for bounding_box in bounding_boxes:\n","    x, y, w, h = bounding_box\n","    cv2.rectangle(resized_image2_rgb, (x, y), (x + w, y + h), (0, 255, 0), 2)  # Warna bounding box hijau\n","\n","# Display the image with the bounding boxes\n","plt.imshow(resized_image2_rgb)\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"a6OI8mo8eRjU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Hasil Segmentasi Bounding yang Telah Terpisah**"],"metadata":{"id":"ucweXs3CFXoY"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","cropped_images = []\n","padding = 20\n","\n","for bounding_box in bounding_boxes:\n","    x, y, w, h = bounding_box\n","    cropped_image = eroded_image[y:y+h, x:x+w]\n","\n","    # Determine the background color for padding\n","    background_color = np.mean(cropped_image)\n","\n","    # Add padding to the cropped image with the background color\n","    padded_image = cv2.copyMakeBorder(cropped_image, padding, padding, padding, padding, cv2.BORDER_CONSTANT, value=255)\n","\n","    cropped_images.append(padded_image)\n","\n","    # Skip displaying the first output\n","    if bounding_box == bounding_boxes[0]:\n","        continue\n","\n","    plt.imshow(padded_image, cmap='gray')\n","    plt.axis('off')\n","    plt.show()\n"],"metadata":{"id":"UMR4hD9sBjVJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Jumlah Hasil Segmentasi Bounding Box yang Telah Terpisah**"],"metadata":{"id":"vhTHuqW6Fr3x"}},{"cell_type":"code","source":["num_segmented = len(cropped_images)\n","print(\"Jumlah hasil segmentasi yang tercrop: \", num_segmented)"],"metadata":{"id":"7WDutsNsEZKi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**Tingkat Akurasi Hasil Segmentasi Bounding Box Secara Keseluruhan**"],"metadata":{"id":"UjLd0Ku3F4GZ"}},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","def calculate_accuracy(segmented_image, ground_truth):\n","    # Hitung jumlah piksel yang sama antara hasil segmentasi dan ground truth\n","    intersection = cv2.bitwise_and(segmented_image, ground_truth)\n","    intersection_pixels = np.count_nonzero(intersection)\n","\n","    # Hitung jumlah piksel yang ada di hasil segmentasi dan ground truth\n","    union = cv2.bitwise_or(segmented_image, ground_truth)\n","    union_pixels = np.count_nonzero(union)\n","\n","    # Hitung tingkat akurasi\n","    accuracy = intersection_pixels / union_pixels * 100\n","    return accuracy\n","\n","# Load ground truth\n","ground_truth = cv2.imread('Hal6.jpg', cv2.IMREAD_GRAYSCALE)\n","\n","# Inisialisasi list untuk menyimpan tingkat akurasi segmentasi tiap cropped image\n","accuracies = []\n","\n","# Crop dan hitung tingkat akurasi segmentasi untuk setiap cropped image\n","for i, cropped_image in enumerate(cropped_images):\n","    # Resize cropped image untuk sesuaikan ukuran dengan ground truth\n","    resized_cropped_image = cv2.resize(cropped_image, (ground_truth.shape[1], ground_truth.shape[0]))\n","\n","    # Hitung tingkat akurasi segmentasi\n","    accuracy = calculate_accuracy(resized_cropped_image, ground_truth)\n","    accuracies.append(accuracy)\n","\n","    # Melewati hasil output pertama kali\n","    if i == 0:\n","        continue\n","\n","    # Tampilkan cropped image dan tingkat akurasi segmentasi\n","    plt.figure()\n","    plt.subplot(1, 2, 1)\n","    plt.imshow(resized_cropped_image, cmap='gray')\n","    plt.axis('off')\n","    plt.title('Cropped Image')\n","    plt.subplot(1, 2, 2)\n","    plt.imshow(ground_truth, cmap='gray')\n","    plt.axis('off')\n","    plt.title('Ground Truth')\n","    plt.show()\n","\n","# Tampilkan tingkat akurasi segmentasi untuk setiap cropped image\n","for i, accuracy in enumerate(accuracies):\n","    print(\"Tingkat akurasi segmentasi ke-{}: {:.2f}%\".format(i+1, accuracy))\n","\n","# Hitung rata-rata tingkat akurasi segmentasi\n","average_accuracy = np.mean(accuracies)\n","\n","# Tampilkan rata-rata tingkat akurasi segmentasi\n","print(\"Rata-rata tingkat akurasi segmentasi: {:.2f}%\".format(average_accuracy))\n"],"metadata":{"id":"EC8dfNQKHT-k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Metode yang digunakan untuk menghitung tingkat akurasi hasil segmentasi bounding box adalah calculate_accuracy. Metode ini menghitung persentase kesamaan antara hasil segmentasi (masked_image) dengan ground truth (ground_truth) menggunakan operasi bitwise AND dan bitwise OR. Persentase kesamaan ini merupakan metrik untuk mengukur tingkat akurasi segmentasi bounding box."],"metadata":{"id":"epGXn7gJHKrh"}}]}